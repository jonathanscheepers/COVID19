{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit6d5b94c2ec1f4c3aacebeb2f43447b95",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta  \n",
    "import dateutil.parser\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import fsolve\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time horizon D+x for making regression predictions\n",
    "Prediction_Horizon = 14\n",
    "## Starting point for minimal number of confirmed cases\n",
    "Min_Confirmed = 10\n",
    "\n",
    "## Number of days used for making the linear prediction\n",
    "Days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "827391"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "url = 'https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv'\n",
    "myfile = requests.get(url)\n",
    "open(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', 'wb').write(myfile.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', sep = ',')\n",
    "data = data[1:]\n",
    "\n",
    "## Choosing the columns for later use\n",
    "data = data.filter(['Country/Region', 'Date', 'Value'])\n",
    "## Renaming the columns we are going to use\n",
    "data.columns = ['Country', 'Date', 'Value']\n",
    "## Transforming the value to int\n",
    "data['Value'] = data['Value'].astype(int)\n",
    "data['Date'] = data['Date'].astype('datetime64[D]')\n",
    "## Summing values for 'Value' for which there are multiple records for one coutry on one day\n",
    "data['Total'] = data.groupby(['Country', 'Date'])['Value'].transform('sum')\n",
    "## Delete the duplicate records\n",
    "data = data.drop_duplicates(subset=['Country', 'Date'])\n",
    "## Sort the value from earliest to latest\n",
    "data = data.sort_values(['Date'], ascending = True)\n",
    "data.columns = ['Country', 'Date', 'Value', 'Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the dates of which no infections were reported\n",
    "data = data[data['Confirmed'] > Min_Confirmed]\n",
    "\n",
    "## Transform the date from Excel numbers to Python dates\n",
    "data['Date'] = data['Date'].astype('datetime64[D]') \n",
    "data['Date'] = data['Date'].dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "data['Time'] = 1\n",
    "data = data.sort_values(by=['Country', 'Confirmed'])\n",
    "data.index = range(len(data))\n",
    "\n",
    "for index, row in data.iloc[1:].iterrows():\n",
    "    if data.loc[index, 'Country'] == data.loc[(int(index) - 1), 'Country']: \n",
    "        data_new = data[data.Country.eq(data.loc[index, 'Country'])]\n",
    "        HighestForCountry = data_new['Time'].max()\n",
    "        data.loc[index, 'Time'] = HighestForCountry + 1\n",
    "    else:\n",
    "        data.loc[index, 'Time'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Countries = data['Country'].tolist()\n",
    "Countries = list(dict.fromkeys(Countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_Data = pd.DataFrame()\n",
    "\n",
    "## For each country, find the 'Time' reference since patient 1, and the corrsponding date\n",
    "for Country in Countries:\n",
    "    data_sub = data[data['Country'].eq(Country)]\n",
    "    Current_Horizon = int(max(data_sub['Time']))\n",
    "    Days = Current_Horizon\n",
    "    FindDate = data_sub['Date'].iloc[-1]\n",
    "    FindDate = datetime.strptime(FindDate, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "    MaxDate = dateutil.parser.parse(FindDate).date()\n",
    "\n",
    "## For each country, add the number of days to the prediction horizon of the dataset based on the 'Time' reference and date\n",
    "    for i in range(Prediction_Horizon):\n",
    "        New_Time = int(max(data_sub['Time'])) + 1\n",
    "        Days_Delay = (New_Time - Current_Horizon)\n",
    "        New_Date = MaxDate + timedelta(days = Days_Delay)\n",
    "        New_Date = New_Date.strftime(\"%d/%m/%Y\")\n",
    "        data_sub = data_sub.append({'Country': Country,'Date': New_Date, 'Time': New_Time},ignore_index=True)\n",
    "    Full_Data = pd.concat([Full_Data,data_sub]) \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_sigmoid(x, a, b, c):\n",
    "    # a = sigmoid midpoint\n",
    "    # b = curve steepness (logistic growth)\n",
    "    # c = max value\n",
    "        return (c / (1 + np.exp(-b*(x-a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "## building the model per country\n",
    "Pred0_Data = pd.DataFrame()\n",
    "for Country in Countries:\n",
    "    data_cntry = Full_Data[Full_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 0:\n",
    "        try:\n",
    "            \n",
    "            data_cntry = data_cntry[['Country', 'Time','Confirmed','Date']]\n",
    "  \n",
    "            Model_Data = data_cntry.dropna()\n",
    "            x = Model_Data['Time'].values\n",
    "            y = Model_Data['Confirmed'].values\n",
    "\n",
    "            popt_sig, pcov_sig = curve_fit(f_sigmoid, x, y, method='dogbox', bounds=([20., 0.001, y.mean()],[60., 2.5, 10*y.max()]), maxfev=5000)\n",
    "\n",
    "            Pred_Length = data_cntry['Confirmed'].values\n",
    "\n",
    "            x_m = np.arange(len(Pred_Length))\n",
    "            y_m = f_sigmoid(x_m, *popt_sig)\n",
    "\n",
    "            data_cntry['Logistic Prediction']=pd.Series(y_m)\n",
    "\n",
    "            Pred0_Data = pd.concat([Pred0_Data,data_cntry]) \n",
    "\n",
    "        except:\n",
    "           continue\n",
    "\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Polynomial_Regression(t):\n",
    "    return pol_reg.predict(poly_reg.fit_transform([[t]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## building the model per country\n",
    "Pred1_Data = pd.DataFrame()\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Pred0_Data[Pred0_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 8:\n",
    "        try:\n",
    "            Model_Data = data_cntry.dropna()\n",
    "            Model_Data = Model_Data[['Time','Confirmed']]\n",
    "\n",
    "            X = Model_Data[['Time']]\n",
    "            y = Model_Data[['Confirmed']]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=0)\n",
    "\n",
    "            poly_reg = PolynomialFeatures(degree=4)\n",
    "            X_poly = poly_reg.fit_transform(X)\n",
    "            pol_reg = LinearRegression()\n",
    "            pol_reg.fit(X_poly, y)\n",
    "\n",
    "            ## This code transforms the regression coefficients into floats to use in our prediction function\n",
    "\n",
    "            data_cntry.insert(5,'Polynomial Prediction',0)\n",
    "            data_cntry['Polynomial Prediction'] = data_cntry['Time'].apply(Polynomial_Regression)\n",
    "            \n",
    "            ## remove first set of square brackets from prediciton output\n",
    "            data_cntry['Polynomial Prediction'] = data_cntry['Polynomial Prediction'].str[0]\n",
    "            ## remove second set of square brackets from prediciton output\n",
    "            data_cntry['Polynomial Prediction'] = data_cntry['Polynomial Prediction'].str[0]\n",
    "            ## \n",
    "            data_cntry['Polynomial Prediction'] =  data_cntry['Polynomial Prediction'].astype(float)\n",
    "\n",
    "            Pred1_Data = pd.concat([Pred1_Data,data_cntry]) \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_predictions(t):\n",
    "    return np.exp(Constant_Coefficient) * np.exp(Time_Coeffificient) ** t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 2 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 2 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 2 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
    }
   ],
   "source": [
    "## building the model per country\n",
    "Pred2_Data = pd.DataFrame()\n",
    "\n",
    "Pred1_Data['logConfirmed'] = np.log(Pred1_Data.Confirmed)\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Pred1_Data[Pred1_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 8:\n",
    "        try:\n",
    "            Model_Data = data_cntry.dropna()\n",
    "            Last_Date = int(max(Model_Data['Time']))\n",
    "            Days_Delay = (Last_Date - Days)\n",
    "            Model_Data = Model_Data.iloc[Days_Delay:]\n",
    "\n",
    "            X = Model_Data.Time\n",
    "            X = sm.add_constant(X)\n",
    "            y = Model_Data.logConfirmed\n",
    "\n",
    "            mod = sm.OLS(y, X)\n",
    "            res = mod.fit()\n",
    "            results_summary = res.summary()\n",
    "            \n",
    "            ## This code transforms the regression coefficients into floats to use in our prediction function\n",
    "            results_as_html = results_summary.tables[1].as_html()\n",
    "            New_DF = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "            Constant_Coefficient = New_DF.at['const','coef']\n",
    "            Time_Coeffificient = New_DF.at['Time','coef']\n",
    "\n",
    "            data_cntry['Linear Prediction'] = data_cntry.Time.apply(linear_predictions)\n",
    "    \n",
    "            Pred2_Data = pd.concat([Pred2_Data,data_cntry]) \n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Country  Time  Confirmed        Date  Logistic Prediction  \\\n0   Afghanistan     1       11.0  14/03/2020         8.420491e+00   \n1   Afghanistan     2       16.0  15/03/2020         1.010630e+01   \n2   Afghanistan     3       21.0  16/03/2020         1.212575e+01   \n3   Afghanistan     4       22.0  17/03/2020         1.454314e+01   \n4   Afghanistan     5       22.0  18/03/2020         1.743447e+01   \n..          ...   ...        ...         ...                  ...   \n19       Zambia    20        NaN  13/04/2020         8.250826e-10   \n20       Zambia    21        NaN  14/04/2020         2.881261e-09   \n21       Zambia    22        NaN  15/04/2020         1.006162e-08   \n22       Zambia    23        NaN  16/04/2020         3.513607e-08   \n23       Zambia    24        NaN  17/04/2020         1.226983e-07   \n\n    Polynomial Prediction  logConfirmed  Linear Prediction  \n0               14.985846      2.397895          16.003381  \n1               15.001318      2.772589          18.496842  \n2               15.869337      3.044522          21.378805  \n3               17.613556      3.091042          24.709802  \n4               20.276083      3.091042          28.559796  \n..                    ...           ...                ...  \n19             391.351399           NaN         160.581243  \n20             507.136364           NaN         181.453605  \n21             648.961538           NaN         205.038958  \n22             820.389860           NaN         231.689937  \n23            1025.204545           NaN         261.805013  \n\n[5536 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Time</th>\n      <th>Confirmed</th>\n      <th>Date</th>\n      <th>Logistic Prediction</th>\n      <th>Polynomial Prediction</th>\n      <th>logConfirmed</th>\n      <th>Linear Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>14/03/2020</td>\n      <td>8.420491e+00</td>\n      <td>14.985846</td>\n      <td>2.397895</td>\n      <td>16.003381</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afghanistan</td>\n      <td>2</td>\n      <td>16.0</td>\n      <td>15/03/2020</td>\n      <td>1.010630e+01</td>\n      <td>15.001318</td>\n      <td>2.772589</td>\n      <td>18.496842</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>3</td>\n      <td>21.0</td>\n      <td>16/03/2020</td>\n      <td>1.212575e+01</td>\n      <td>15.869337</td>\n      <td>3.044522</td>\n      <td>21.378805</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Afghanistan</td>\n      <td>4</td>\n      <td>22.0</td>\n      <td>17/03/2020</td>\n      <td>1.454314e+01</td>\n      <td>17.613556</td>\n      <td>3.091042</td>\n      <td>24.709802</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Afghanistan</td>\n      <td>5</td>\n      <td>22.0</td>\n      <td>18/03/2020</td>\n      <td>1.743447e+01</td>\n      <td>20.276083</td>\n      <td>3.091042</td>\n      <td>28.559796</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Zambia</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>13/04/2020</td>\n      <td>8.250826e-10</td>\n      <td>391.351399</td>\n      <td>NaN</td>\n      <td>160.581243</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Zambia</td>\n      <td>21</td>\n      <td>NaN</td>\n      <td>14/04/2020</td>\n      <td>2.881261e-09</td>\n      <td>507.136364</td>\n      <td>NaN</td>\n      <td>181.453605</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Zambia</td>\n      <td>22</td>\n      <td>NaN</td>\n      <td>15/04/2020</td>\n      <td>1.006162e-08</td>\n      <td>648.961538</td>\n      <td>NaN</td>\n      <td>205.038958</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Zambia</td>\n      <td>23</td>\n      <td>NaN</td>\n      <td>16/04/2020</td>\n      <td>3.513607e-08</td>\n      <td>820.389860</td>\n      <td>NaN</td>\n      <td>231.689937</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Zambia</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>17/04/2020</td>\n      <td>1.226983e-07</td>\n      <td>1025.204545</td>\n      <td>NaN</td>\n      <td>261.805013</td>\n    </tr>\n  </tbody>\n</table>\n<p>5536 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "Pred2_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Country  Time  Confirmed        Date  Logistic Prediction  \\\n0   Afghanistan     1       11.0  14/03/2020         8.420491e+00   \n1   Afghanistan     2       16.0  15/03/2020         1.010630e+01   \n2   Afghanistan     3       21.0  16/03/2020         1.212575e+01   \n3   Afghanistan     4       22.0  17/03/2020         1.454314e+01   \n4   Afghanistan     5       22.0  18/03/2020         1.743447e+01   \n..          ...   ...        ...         ...                  ...   \n5        Zambia     6       35.0  30/03/2020         2.057330e-17   \n6        Zambia     7       35.0  31/03/2020         7.184378e-17   \n7        Zambia     8       36.0  01/04/2020         2.508848e-16   \n8        Zambia     9       39.0  02/04/2020         8.761121e-16   \n9        Zambia    10       39.0  03/04/2020         3.059461e-15   \n\n    Polynomial Prediction  logConfirmed  Linear Prediction  \n0               14.985846      2.397895          16.003381  \n1               15.001318      2.772589          18.496842  \n2               15.869337      3.044522          21.378805  \n3               17.613556      3.091042          24.709802  \n4               20.276083      3.091042          28.559796  \n..                    ...           ...                ...  \n5               33.604895      3.555348          29.020428  \n6               35.578671      3.555348          32.792506  \n7               36.840909      3.583519          37.054878  \n8               37.870629      3.663562          41.871274  \n9               39.367133      3.663562          47.313705  \n\n[3548 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Time</th>\n      <th>Confirmed</th>\n      <th>Date</th>\n      <th>Logistic Prediction</th>\n      <th>Polynomial Prediction</th>\n      <th>logConfirmed</th>\n      <th>Linear Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>14/03/2020</td>\n      <td>8.420491e+00</td>\n      <td>14.985846</td>\n      <td>2.397895</td>\n      <td>16.003381</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afghanistan</td>\n      <td>2</td>\n      <td>16.0</td>\n      <td>15/03/2020</td>\n      <td>1.010630e+01</td>\n      <td>15.001318</td>\n      <td>2.772589</td>\n      <td>18.496842</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>3</td>\n      <td>21.0</td>\n      <td>16/03/2020</td>\n      <td>1.212575e+01</td>\n      <td>15.869337</td>\n      <td>3.044522</td>\n      <td>21.378805</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Afghanistan</td>\n      <td>4</td>\n      <td>22.0</td>\n      <td>17/03/2020</td>\n      <td>1.454314e+01</td>\n      <td>17.613556</td>\n      <td>3.091042</td>\n      <td>24.709802</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Afghanistan</td>\n      <td>5</td>\n      <td>22.0</td>\n      <td>18/03/2020</td>\n      <td>1.743447e+01</td>\n      <td>20.276083</td>\n      <td>3.091042</td>\n      <td>28.559796</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Zambia</td>\n      <td>6</td>\n      <td>35.0</td>\n      <td>30/03/2020</td>\n      <td>2.057330e-17</td>\n      <td>33.604895</td>\n      <td>3.555348</td>\n      <td>29.020428</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Zambia</td>\n      <td>7</td>\n      <td>35.0</td>\n      <td>31/03/2020</td>\n      <td>7.184378e-17</td>\n      <td>35.578671</td>\n      <td>3.555348</td>\n      <td>32.792506</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Zambia</td>\n      <td>8</td>\n      <td>36.0</td>\n      <td>01/04/2020</td>\n      <td>2.508848e-16</td>\n      <td>36.840909</td>\n      <td>3.583519</td>\n      <td>37.054878</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Zambia</td>\n      <td>9</td>\n      <td>39.0</td>\n      <td>02/04/2020</td>\n      <td>8.761121e-16</td>\n      <td>37.870629</td>\n      <td>3.663562</td>\n      <td>41.871274</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Zambia</td>\n      <td>10</td>\n      <td>39.0</td>\n      <td>03/04/2020</td>\n      <td>3.059461e-15</td>\n      <td>39.367133</td>\n      <td>3.663562</td>\n      <td>47.313705</td>\n    </tr>\n  </tbody>\n</table>\n<p>3548 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "Pred2_Data = Pred2_Data.dropna()\n",
    "Countries = Pred2_Data['Country'].tolist()\n",
    "Countries = list(dict.fromkeys(Countries))\n",
    "Pred2_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r_squared(pred,real):\n",
    "    correlation_matrix = np.corrcoef(pred, real)\n",
    "    correlation_xy = correlation_matrix[0,1]\n",
    "    r_squared = correlation_xy**2\n",
    "\n",
    "    return 1-(1-r_squared)*(n-1)/(n-p-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Country  Logistic R2  Linear R2  Polynomial R2\n0           Afghanistan     0.983463   0.982623       0.983699\n1               Albania     0.992650   0.988465       0.994508\n2               Algeria     0.996653   0.996609       0.996420\n3               Andorra     0.205897   0.957664       0.997101\n4             Argentina     0.993357   0.984258       0.995822\n..                  ...          ...        ...            ...\n137          Uzbekistan     0.351400   0.976855       0.992996\n138           Venezuela     0.166634   0.949988       0.989420\n139             Vietnam     0.991450   0.970174       0.998012\n140  West Bank and Gaza     0.978833   0.980709       0.987433\n141              Zambia     0.151027   0.801060       0.987194\n\n[142 rows x 4 columns]\n"
    }
   ],
   "source": [
    "## For each country, find the 'Time' reference since patient 1, and the corrsponding date\n",
    "Output = pd.DataFrame() #Temporary empty dataframe\n",
    "Cols = ['Country', 'Logistic R2', 'Linear R2', 'Polynomial R2']\n",
    "Output = pd.DataFrame(columns = Cols)\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Pred2_Data[Pred2_Data.Country.eq(Country)]\n",
    "\n",
    "    Logŷ = data_cntry['Logistic Prediction'].values\n",
    "    Linŷ = data_cntry['Linear Prediction'].values\n",
    "    Polŷ = data_cntry['Polynomial Prediction'].values\n",
    "    y = data_cntry['Confirmed'].values\n",
    "\n",
    "    n = data_cntry.count(axis='columns').count()\n",
    "    p = 1\n",
    "\n",
    "    LogAdjR2 = adj_r_squared(Logŷ, y)\n",
    "    LinAdjR2 = adj_r_squared(Linŷ, y)\n",
    "    PolAdjR2 = adj_r_squared(Polŷ, y)\n",
    "\n",
    "    Output = Output.append({'Country': Country, 'Logistic R2': LogAdjR2, 'Linear R2': LinAdjR2, 'Polynomial R2': PolAdjR2,}, ignore_index=True)\n",
    "\n",
    "print(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now() # current date and time\n",
    "Now = now.strftime(\"%Y%m%d_%Hh%M\")\n",
    "\n",
    "Pred2_Data.to_csv(f'C:\\\\Users\\\\JMSch\\\\Documents\\\\MEGA\\\\05_Paris\\\\ESCP Business School\\\\MSc Big Data & Business Analytics\\\\COVID19\\\\COVID19\\\\Data\\\\Extracts\\\\ALL_Prediction_Output_Global_{Now}.csv', index = False)\n",
    "\n",
    "Output.to_csv(f'C:\\\\Users\\\\JMSch\\\\Documents\\\\MEGA\\\\05_Paris\\\\ESCP Business School\\\\MSc Big Data & Business Analytics\\\\COVID19\\\\COVID19\\\\Data\\\\Extracts\\\\Predictions_Adjusted_R-Squared_{Now}.csv', index = False)"
   ]
  }
 ]
}