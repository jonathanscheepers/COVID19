{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit6d5b94c2ec1f4c3aacebeb2f43447b95",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta  \n",
    "import dateutil.parser\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import fsolve\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time horizon D+x for making regression predictions\n",
    "Prediction_Horizon = 14\n",
    "## Starting point for minimal number of confirmed cases\n",
    "Min_Confirmed = 10\n",
    "\n",
    "## Number of days used for making the linear prediction\n",
    "Days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "868989"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "url = 'https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv'\n",
    "myfile = requests.get(url)\n",
    "open(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', 'wb').write(myfile.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', sep = ',')\n",
    "data = data[1:]\n",
    "\n",
    "## Choosing the columns for later use\n",
    "data = data.filter(['Country/Region', 'Date', 'Value'])\n",
    "## Renaming the columns we are going to use\n",
    "data.columns = ['Country', 'Date', 'Value']\n",
    "## Transforming the value to int\n",
    "data['Value'] = data['Value'].astype(int)\n",
    "data['Date'] = data['Date'].astype('datetime64[D]')\n",
    "## Summing values for 'Value' for which there are multiple records for one coutry on one day\n",
    "data['Total'] = data.groupby(['Country', 'Date'])['Value'].transform('sum')\n",
    "## Delete the duplicate records\n",
    "data = data.drop_duplicates(subset=['Country', 'Date'])\n",
    "## Sort the value from earliest to latest\n",
    "data = data.sort_values(['Date'], ascending = True)\n",
    "data.columns = ['Country', 'Date', 'Value', 'Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the dates of which no infections were reported\n",
    "data = data[data['Confirmed'] > Min_Confirmed]\n",
    "\n",
    "## Transform the date from Excel numbers to Python dates\n",
    "data['Date'] = data['Date'].astype('datetime64[D]') \n",
    "data['Date'] = data['Date'].dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "data['Time'] = 1\n",
    "data = data.sort_values(by=['Country', 'Confirmed'])\n",
    "data.index = range(len(data))\n",
    "\n",
    "for index, row in data.iloc[1:].iterrows():\n",
    "    if data.loc[index, 'Country'] == data.loc[(int(index) - 1), 'Country']: \n",
    "        data_new = data[data.Country.eq(data.loc[index, 'Country'])]\n",
    "        HighestForCountry = data_new['Time'].max()\n",
    "        data.loc[index, 'Time'] = HighestForCountry + 1\n",
    "    else:\n",
    "        data.loc[index, 'Time'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Countries = data['Country'].tolist()\n",
    "Countries = list(dict.fromkeys(Countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_Data = pd.DataFrame()\n",
    "\n",
    "## For each country, find the 'Time' reference since patient 1, and the corrsponding date\n",
    "for Country in Countries:\n",
    "    data_sub = data[data['Country'].eq(Country)]\n",
    "    Current_Horizon = int(max(data_sub['Time']))\n",
    "    Days = Current_Horizon\n",
    "    FindDate = data_sub['Date'].iloc[-1]\n",
    "    FindDate = datetime.strptime(FindDate, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "    MaxDate = dateutil.parser.parse(FindDate).date()\n",
    "\n",
    "## For each country, add the number of days to the prediction horizon of the dataset based on the 'Time' reference and date\n",
    "    for i in range(Prediction_Horizon):\n",
    "        New_Time = int(max(data_sub['Time'])) + 1\n",
    "        Days_Delay = (New_Time - Current_Horizon)\n",
    "        New_Date = MaxDate + timedelta(days = Days_Delay)\n",
    "        New_Date = New_Date.strftime(\"%d/%m/%Y\")\n",
    "        data_sub = data_sub.append({'Country': Country,'Date': New_Date, 'Time': New_Time},ignore_index=True)\n",
    "    Full_Data = pd.concat([Full_Data,data_sub]) \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_sigmoid(x, a, b, c):\n",
    "    # a = sigmoid midpoint\n",
    "    # b = curve steepness (logistic growth)\n",
    "    # c = max value\n",
    "        return (c / (1 + np.exp(-b*(x-a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "## building the model per country\n",
    "Pred0_Data = pd.DataFrame()\n",
    "for Country in Countries:\n",
    "    data_cntry = Full_Data[Full_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 0:\n",
    "        try:\n",
    "            \n",
    "            data_cntry = data_cntry[['Country', 'Time','Confirmed','Date']]\n",
    "  \n",
    "            Model_Data = data_cntry.dropna()\n",
    "            x = Model_Data['Time'].values\n",
    "            y = Model_Data['Confirmed'].values\n",
    "\n",
    "            popt_sig, pcov_sig = curve_fit(f_sigmoid, x, y, method='dogbox', bounds=([20., 0.001, y.mean()],[60., 2.5, 10*y.max()]), maxfev=5000)\n",
    "\n",
    "            Pred_Length = data_cntry['Confirmed'].values\n",
    "\n",
    "            x_m = np.arange(len(Pred_Length))\n",
    "            y_m = f_sigmoid(x_m, *popt_sig)\n",
    "\n",
    "            data_cntry['Logistic Prediction']=pd.Series(y_m)\n",
    "\n",
    "            Pred0_Data = pd.concat([Pred0_Data,data_cntry]) \n",
    "\n",
    "        except:\n",
    "           continue\n",
    "\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Polynomial_Regression(t):\n",
    "    return pol_reg.predict(poly_reg.fit_transform([[t]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## building the model per country\n",
    "Pred1_Data = pd.DataFrame()\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Pred0_Data[Pred0_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 8:\n",
    "        try:\n",
    "            Model_Data = data_cntry.dropna()\n",
    "            Model_Data = Model_Data[['Time','Confirmed']]\n",
    "\n",
    "            X = Model_Data[['Time']]\n",
    "            y = Model_Data[['Confirmed']]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=0)\n",
    "\n",
    "            poly_reg = PolynomialFeatures(degree=4)\n",
    "            X_poly = poly_reg.fit_transform(X)\n",
    "            pol_reg = LinearRegression()\n",
    "            pol_reg.fit(X_poly, y)\n",
    "\n",
    "            ## This code transforms the regression coefficients into floats to use in our prediction function\n",
    "\n",
    "            data_cntry.insert(5,'Polynomial Prediction',0)\n",
    "            data_cntry['Polynomial Prediction'] = data_cntry['Time'].apply(Polynomial_Regression)\n",
    "            \n",
    "            ## remove first set of square brackets from prediciton output\n",
    "            data_cntry['Polynomial Prediction'] = data_cntry['Polynomial Prediction'].str[0]\n",
    "            ## remove second set of square brackets from prediciton output\n",
    "            data_cntry['Polynomial Prediction'] = data_cntry['Polynomial Prediction'].str[0]\n",
    "            ## \n",
    "            data_cntry['Polynomial Prediction'] =  data_cntry['Polynomial Prediction'].astype(float)\n",
    "\n",
    "            Pred1_Data = pd.concat([Pred1_Data,data_cntry]) \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_predictions(t):\n",
    "    return np.exp(Constant_Coefficient) * np.exp(Time_Coeffificient) ** t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 2 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 6 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 2 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 6 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
    }
   ],
   "source": [
    "## building the model per country\n",
    "Pred2_Data = pd.DataFrame()\n",
    "\n",
    "Pred1_Data['logConfirmed'] = np.log(Pred1_Data.Confirmed)\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Pred1_Data[Pred1_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 8:\n",
    "        try:\n",
    "            Model_Data = data_cntry.dropna()\n",
    "            Last_Date = int(max(Model_Data['Time']))\n",
    "            Days_Delay = (Last_Date - Days)\n",
    "            Model_Data = Model_Data.iloc[Days_Delay:]\n",
    "\n",
    "            X = Model_Data.Time\n",
    "            X = sm.add_constant(X)\n",
    "            y = Model_Data.logConfirmed\n",
    "\n",
    "            mod = sm.OLS(y, X)\n",
    "            res = mod.fit()\n",
    "            results_summary = res.summary()\n",
    "            \n",
    "            ## This code transforms the regression coefficients into floats to use in our prediction function\n",
    "            results_as_html = results_summary.tables[1].as_html()\n",
    "            New_DF = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "            Constant_Coefficient = New_DF.at['const','coef']\n",
    "            Time_Coeffificient = New_DF.at['Time','coef']\n",
    "\n",
    "            data_cntry['Linear Prediction'] = data_cntry.Time.apply(linear_predictions)\n",
    "    \n",
    "            Pred2_Data = pd.concat([Pred2_Data,data_cntry]) \n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Country  Time  Confirmed        Date  Logistic Prediction  \\\n0   Afghanistan     1       11.0  14/03/2020         9.738709e+01   \n1   Afghanistan     2       16.0  15/03/2020         9.769231e+01   \n2   Afghanistan     3       21.0  16/03/2020         9.799779e+01   \n3   Afghanistan     4       22.0  17/03/2020         9.830352e+01   \n4   Afghanistan     5       22.0  18/03/2020         9.860951e+01   \n..          ...   ...        ...         ...                  ...   \n21       Zambia    22        NaN  15/04/2020         1.010123e-08   \n22       Zambia    23        NaN  16/04/2020         3.527440e-08   \n23       Zambia    24        NaN  17/04/2020         1.231813e-07   \n24       Zambia    25        NaN  18/04/2020         4.301601e-07   \n25       Zambia    26        NaN  19/04/2020         1.502157e-06   \n\n    Polynomial Prediction  logConfirmed  Linear Prediction  \n0               12.807358      2.397895          17.801808  \n1               15.469413      2.772589          20.421740  \n2               17.503527      3.044522          23.427253  \n3               19.377318      3.091042          26.875094  \n4               21.517403      3.091042          30.830363  \n..                    ...           ...                ...  \n21             122.960373           NaN         127.077864  \n22             151.435897           NaN         139.798206  \n23             186.337995           NaN         153.791840  \n24             228.513403           NaN         169.186220  \n25             278.856061           NaN         186.121558  \n\n[5808 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Time</th>\n      <th>Confirmed</th>\n      <th>Date</th>\n      <th>Logistic Prediction</th>\n      <th>Polynomial Prediction</th>\n      <th>logConfirmed</th>\n      <th>Linear Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>14/03/2020</td>\n      <td>9.738709e+01</td>\n      <td>12.807358</td>\n      <td>2.397895</td>\n      <td>17.801808</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afghanistan</td>\n      <td>2</td>\n      <td>16.0</td>\n      <td>15/03/2020</td>\n      <td>9.769231e+01</td>\n      <td>15.469413</td>\n      <td>2.772589</td>\n      <td>20.421740</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>3</td>\n      <td>21.0</td>\n      <td>16/03/2020</td>\n      <td>9.799779e+01</td>\n      <td>17.503527</td>\n      <td>3.044522</td>\n      <td>23.427253</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Afghanistan</td>\n      <td>4</td>\n      <td>22.0</td>\n      <td>17/03/2020</td>\n      <td>9.830352e+01</td>\n      <td>19.377318</td>\n      <td>3.091042</td>\n      <td>26.875094</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Afghanistan</td>\n      <td>5</td>\n      <td>22.0</td>\n      <td>18/03/2020</td>\n      <td>9.860951e+01</td>\n      <td>21.517403</td>\n      <td>3.091042</td>\n      <td>30.830363</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Zambia</td>\n      <td>22</td>\n      <td>NaN</td>\n      <td>15/04/2020</td>\n      <td>1.010123e-08</td>\n      <td>122.960373</td>\n      <td>NaN</td>\n      <td>127.077864</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Zambia</td>\n      <td>23</td>\n      <td>NaN</td>\n      <td>16/04/2020</td>\n      <td>3.527440e-08</td>\n      <td>151.435897</td>\n      <td>NaN</td>\n      <td>139.798206</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Zambia</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>17/04/2020</td>\n      <td>1.231813e-07</td>\n      <td>186.337995</td>\n      <td>NaN</td>\n      <td>153.791840</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Zambia</td>\n      <td>25</td>\n      <td>NaN</td>\n      <td>18/04/2020</td>\n      <td>4.301601e-07</td>\n      <td>228.513403</td>\n      <td>NaN</td>\n      <td>169.186220</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Zambia</td>\n      <td>26</td>\n      <td>NaN</td>\n      <td>19/04/2020</td>\n      <td>1.502157e-06</td>\n      <td>278.856061</td>\n      <td>NaN</td>\n      <td>186.121558</td>\n    </tr>\n  </tbody>\n</table>\n<p>5808 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "Pred3_Data = Pred2_Data.dropna()\n",
    "Countries = Pred2_Data['Country'].tolist()\n",
    "Countries = list(dict.fromkeys(Countries))\n",
    "Pred2_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r_squared(pred,real):\n",
    "    correlation_matrix = np.corrcoef(pred, real)\n",
    "    correlation_xy = correlation_matrix[0,1]\n",
    "    r_squared = correlation_xy**2\n",
    "\n",
    "    return 1-(1-r_squared)*(n-1)/(n-p-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Country  Logistic R2  Linear R2  Polynomial R2\n0            Afghanistan     0.864574   0.982612       0.988279\n1                Albania     0.993133   0.991358       0.994297\n2                Algeria     0.995731   0.992979       0.995675\n3                Andorra     0.959583   0.953878       0.996778\n4    Antigua and Barbuda          NaN        NaN            NaN\n..                   ...          ...        ...            ...\n140           Uzbekistan     0.985675   0.985596       0.987171\n141            Venezuela     0.941921   0.939861       0.991484\n142              Vietnam     0.992831   0.962815       0.996687\n143   West Bank and Gaza     0.980767   0.986461       0.992788\n144               Zambia     0.059151   0.727923       0.988368\n\n[145 rows x 4 columns]\n"
    }
   ],
   "source": [
    "## For each country, find the 'Time' reference since patient 1, and the corrsponding date\n",
    "Output = pd.DataFrame() #Temporary empty dataframe\n",
    "Cols = ['Country', 'Logistic R2', 'Linear R2', 'Polynomial R2']\n",
    "Output = pd.DataFrame(columns = Cols)\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Pred3_Data[Pred3_Data.Country.eq(Country)]\n",
    "\n",
    "    Logŷ = data_cntry['Logistic Prediction'].values\n",
    "    Linŷ = data_cntry['Linear Prediction'].values\n",
    "    Polŷ = data_cntry['Polynomial Prediction'].values\n",
    "    y = data_cntry['Confirmed'].values\n",
    "\n",
    "    n = data_cntry.count(axis='columns').count()\n",
    "    p = 1\n",
    "\n",
    "    LogAdjR2 = adj_r_squared(Logŷ, y)\n",
    "    LinAdjR2 = adj_r_squared(Linŷ, y)\n",
    "    PolAdjR2 = adj_r_squared(Polŷ, y)\n",
    "\n",
    "    Output = Output.append({'Country': Country, 'Logistic R2': LogAdjR2, 'Linear R2': LinAdjR2, 'Polynomial R2': PolAdjR2,}, ignore_index=True)\n",
    "\n",
    "print(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now() # current date and time\n",
    "Now = now.strftime(\"%Y%m%d_%Hh%M\")\n",
    "\n",
    "Pred2_Data.to_csv(f'C:\\\\Users\\\\JMSch\\\\Documents\\\\MEGA\\\\05_Paris\\\\ESCP Business School\\\\MSc Big Data & Business Analytics\\\\COVID19\\\\COVID19\\\\Data\\\\Extracts\\\\ALL_Prediction_Output_Global_{Now}.csv', index = False)\n",
    "\n",
    "Output.to_csv(f'C:\\\\Users\\\\JMSch\\\\Documents\\\\MEGA\\\\05_Paris\\\\ESCP Business School\\\\MSc Big Data & Business Analytics\\\\COVID19\\\\COVID19\\\\Data\\\\Extracts\\\\Predictions_Adjusted_R-Squared_{Now}.csv', index = False)"
   ]
  }
 ]
}