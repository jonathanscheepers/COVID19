{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit6d5b94c2ec1f4c3aacebeb2f43447b95",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta  \n",
    "import dateutil.parser\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import fsolve\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time horizon D+x for making regression predictions\n",
    "Prediction_Horizon = 14\n",
    "## Starting point for minimal number of confirmed cases\n",
    "Min_Confirmed = 10\n",
    "\n",
    "## Number of days used for making the linear prediction\n",
    "Days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "896723"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "url = 'https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv'\n",
    "myfile = requests.get(url)\n",
    "open(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', 'wb').write(myfile.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', sep = ',')\n",
    "data = data[1:]\n",
    "\n",
    "## Choosing the columns for later use\n",
    "data = data.filter(['Country/Region', 'Date', 'Value'])\n",
    "## Renaming the columns we are going to use\n",
    "data.columns = ['Country', 'Date', 'Value']\n",
    "## Transforming the value to int\n",
    "data['Value'] = data['Value'].astype(int)\n",
    "data['Date'] = data['Date'].astype('datetime64[D]')\n",
    "## Summing values for 'Value' for which there are multiple records for one coutry on one day\n",
    "data['Total'] = data.groupby(['Country', 'Date'])['Value'].transform('sum')\n",
    "## Delete the duplicate records\n",
    "data = data.drop_duplicates(subset=['Country', 'Date'])\n",
    "## Sort the value from earliest to latest\n",
    "data = data.sort_values(['Date'], ascending = True)\n",
    "data.columns = ['Country', 'Date', 'Value', 'Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the dates of which no infections were reported\n",
    "data = data[data['Confirmed'] > Min_Confirmed]\n",
    "\n",
    "## Transform the date from Excel numbers to Python dates\n",
    "data['Date'] = data['Date'].astype('datetime64[D]') \n",
    "data['Date'] = data['Date'].dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "data['Time'] = 1\n",
    "data = data.sort_values(by=['Country', 'Confirmed'])\n",
    "data.index = range(len(data))\n",
    "\n",
    "for index, row in data.iloc[1:].iterrows():\n",
    "    if data.loc[index, 'Country'] == data.loc[(int(index) - 1), 'Country']: \n",
    "        data_new = data[data.Country.eq(data.loc[index, 'Country'])]\n",
    "        HighestForCountry = data_new['Time'].max()\n",
    "        data.loc[index, 'Time'] = HighestForCountry + 1\n",
    "    else:\n",
    "        data.loc[index, 'Time'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Countries = data['Country'].tolist()\n",
    "Countries = list(dict.fromkeys(Countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_Data = pd.DataFrame()\n",
    "\n",
    "## For each country, find the 'Time' reference since patient 1, and the corrsponding date\n",
    "for Country in Countries:\n",
    "    data_sub = data[data['Country'].eq(Country)]\n",
    "    Current_Horizon = int(max(data_sub['Time']))\n",
    "    Days = Current_Horizon\n",
    "    FindDate = data_sub['Date'].iloc[-1]\n",
    "    FindDate = datetime.strptime(FindDate, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "    MaxDate = dateutil.parser.parse(FindDate).date()\n",
    "\n",
    "## For each country, add the number of days to the prediction horizon of the dataset based on the 'Time' reference and date\n",
    "    for i in range(Prediction_Horizon):\n",
    "        New_Time = int(max(data_sub['Time'])) + 1\n",
    "        Days_Delay = (New_Time - Current_Horizon)\n",
    "        New_Date = MaxDate + timedelta(days = Days_Delay)\n",
    "        New_Date = New_Date.strftime(\"%d/%m/%Y\")\n",
    "        data_sub = data_sub.append({'Country': Country,'Date': New_Date, 'Time': New_Time},ignore_index=True)\n",
    "    Full_Data = pd.concat([Full_Data,data_sub]) \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_sigmoid(x, a, b, c):\n",
    "    # a = sigmoid midpoint\n",
    "    # b = curve steepness (logistic growth)\n",
    "    # c = max value\n",
    "        return (c / (1 + np.exp(-b*(x-a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "## building the model per country\n",
    "Pred0_Data = pd.DataFrame()\n",
    "for Country in Countries:\n",
    "    data_cntry = Full_Data[Full_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 0:\n",
    "        try:\n",
    "            \n",
    "            data_cntry = data_cntry[['Country', 'Time','Confirmed','Date']]\n",
    "  \n",
    "            Model_Data = data_cntry.dropna()\n",
    "            x = Model_Data['Time'].values\n",
    "            y = Model_Data['Confirmed'].values\n",
    "\n",
    "            popt_sig, pcov_sig = curve_fit(f_sigmoid, x, y, method='dogbox', bounds=([20., 0.001, y.mean()],[60., 2.5, 10*y.max()]), maxfev=5000)\n",
    "\n",
    "            Pred_Length = data_cntry['Confirmed'].values\n",
    "\n",
    "            x_m = np.arange(len(Pred_Length))\n",
    "            y_m = f_sigmoid(x_m, *popt_sig)\n",
    "\n",
    "            data_cntry['Logistic Prediction']=pd.Series(y_m)\n",
    "\n",
    "            Pred0_Data = pd.concat([Pred0_Data,data_cntry]) \n",
    "\n",
    "        except:\n",
    "           continue\n",
    "\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Polynomial_Regression(t):\n",
    "    return pol_reg.predict(poly_reg.fit_transform([[t]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "## building the model per country\n",
    "Pred1_Data = pd.DataFrame()\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Pred0_Data[Pred0_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 8:\n",
    "        try:\n",
    "            Model_Data = data_cntry.dropna()\n",
    "\n",
    "            Model_Data = Model_Data[['Time','Confirmed']]\n",
    "\n",
    "            X = Model_Data[['Time']]\n",
    "            y = Model_Data[['Confirmed']]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=0)\n",
    "\n",
    "            poly_reg = PolynomialFeatures(degree=4)\n",
    "            X_poly = poly_reg.fit_transform(X)\n",
    "            pol_reg = LinearRegression()\n",
    "            pol_reg.fit(X_poly, y)\n",
    "\n",
    "            ## This code transforms the regression coefficients into floats to use in our prediction function\n",
    "\n",
    "            data_cntry.insert(5,'Polynomial Prediction',0)\n",
    "            data_cntry['Polynomial Prediction'] = data_cntry['Time'].apply(Polynomial_Regression)\n",
    "            \n",
    "            ## remove first set of square brackets from prediciton output\n",
    "            data_cntry['Polynomial Prediction'] = data_cntry['Polynomial Prediction'].str[0]\n",
    "            ## remove second set of square brackets from prediciton output\n",
    "            data_cntry['Polynomial Prediction'] = data_cntry['Polynomial Prediction'].str[0]\n",
    "            ## \n",
    "            data_cntry['Polynomial Prediction'] =  data_cntry['Polynomial Prediction'].astype(float)\n",
    "\n",
    "            Pred1_Data = pd.concat([Pred1_Data, data_cntry]) \n",
    "     \n",
    "\n",
    "        except:       \n",
    "            continue\n",
    "\n",
    "    else:\n",
    "            continue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Country  Time  Confirmed        Date  Logistic Prediction  \\\n0   Afghanistan     1       11.0  14/03/2020         7.670810e+00   \n1   Afghanistan     2       16.0  15/03/2020         9.311701e+00   \n2   Afghanistan     3       21.0  16/03/2020         1.129771e+01   \n3   Afghanistan     4       22.0  17/03/2020         1.369864e+01   \n4   Afghanistan     5       22.0  18/03/2020         1.659715e+01   \n..          ...   ...        ...         ...                  ...   \n23       Zambia    24        NaN  17/04/2020         1.235264e-07   \n24       Zambia    25        NaN  18/04/2020         4.313650e-07   \n25       Zambia    26        NaN  19/04/2020         1.506365e-06   \n26       Zambia    27        NaN  20/04/2020         5.260360e-06   \n27       Zambia    28        NaN  21/04/2020         1.836964e-05   \n\n    Polynomial Prediction  \n0               13.511288  \n1               15.485500  \n2               17.135651  \n3               18.859005  \n4               21.018885  \n..                    ...  \n23             120.015514  \n24             145.083549  \n25             175.261518  \n26             211.151642  \n27             253.385761  \n\n[6262 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Time</th>\n      <th>Confirmed</th>\n      <th>Date</th>\n      <th>Logistic Prediction</th>\n      <th>Polynomial Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>14/03/2020</td>\n      <td>7.670810e+00</td>\n      <td>13.511288</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afghanistan</td>\n      <td>2</td>\n      <td>16.0</td>\n      <td>15/03/2020</td>\n      <td>9.311701e+00</td>\n      <td>15.485500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>3</td>\n      <td>21.0</td>\n      <td>16/03/2020</td>\n      <td>1.129771e+01</td>\n      <td>17.135651</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Afghanistan</td>\n      <td>4</td>\n      <td>22.0</td>\n      <td>17/03/2020</td>\n      <td>1.369864e+01</td>\n      <td>18.859005</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Afghanistan</td>\n      <td>5</td>\n      <td>22.0</td>\n      <td>18/03/2020</td>\n      <td>1.659715e+01</td>\n      <td>21.018885</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Zambia</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>17/04/2020</td>\n      <td>1.235264e-07</td>\n      <td>120.015514</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Zambia</td>\n      <td>25</td>\n      <td>NaN</td>\n      <td>18/04/2020</td>\n      <td>4.313650e-07</td>\n      <td>145.083549</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Zambia</td>\n      <td>26</td>\n      <td>NaN</td>\n      <td>19/04/2020</td>\n      <td>1.506365e-06</td>\n      <td>175.261518</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Zambia</td>\n      <td>27</td>\n      <td>NaN</td>\n      <td>20/04/2020</td>\n      <td>5.260360e-06</td>\n      <td>211.151642</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Zambia</td>\n      <td>28</td>\n      <td>NaN</td>\n      <td>21/04/2020</td>\n      <td>1.836964e-05</td>\n      <td>253.385761</td>\n    </tr>\n  </tbody>\n</table>\n<p>6262 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "Pred1_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_predictions(t):\n",
    "    return np.exp(Constant_Coefficient) * np.exp(Time_Coeffificient) ** t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 7 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 6 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 2 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\nC:\\Python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:70: ValueWarning: omni_normtest is not valid with less than 8 observations; 6 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
    }
   ],
   "source": [
    "## building the model per country\n",
    "Pred2_Data = pd.DataFrame()\n",
    "\n",
    "Pred1_Data['logConfirmed'] = np.log(Pred1_Data.Confirmed)\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Pred1_Data[Pred1_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 8:\n",
    "        try:\n",
    "            Model_Data = data_cntry.dropna()\n",
    "            Last_Date = int(max(Model_Data['Time']))\n",
    "            Days_Delay = (Last_Date - Days)\n",
    "            #Model_Data = Model_Data.iloc[Days_Delay:]\n",
    "            Model_Data = Model_Data[['Time','Confirmed', 'logConfirmed']]\n",
    "\n",
    "            X = Model_Data.Time\n",
    "            X = sm.add_constant(X)\n",
    "            y = Model_Data.logConfirmed\n",
    "\n",
    "\n",
    "            mod = sm.OLS(y, X)\n",
    "            res = mod.fit()\n",
    "            results_summary = res.summary()\n",
    "            \n",
    "            ## This code transforms the regression coefficients into floats to use in our prediction function\n",
    "            results_as_html = results_summary.tables[1].as_html()\n",
    "            New_DF = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "            Constant_Coefficient = New_DF.at['const','coef']\n",
    "            Time_Coeffificient = New_DF.at['Time','coef']\n",
    "\n",
    "            data_cntry['Linear Prediction'] = data_cntry.Time.apply(linear_predictions)\n",
    "\n",
    "    \n",
    "            Pred2_Data = pd.concat([Pred2_Data,data_cntry]) \n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r_squared(pred,real):\n",
    "    correlation_matrix = np.corrcoef(pred, real)\n",
    "    correlation_xy = correlation_matrix[0,1]\n",
    "    r_squared = correlation_xy**2\n",
    "\n",
    "    return 1-(1-r_squared)*(n-1)/(n-p-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Country  Logistic R2  Linear R2  Polynomial R2\n0           Afghanistan     0.991140   0.969715       0.992021\n1               Albania     0.994524   0.957436       0.995590\n2               Algeria     0.995272   0.962235       0.993943\n3               Andorra     0.962502   0.878114       0.997495\n4                Angola     0.540136   0.906341       1.000000\n..                  ...          ...        ...            ...\n154           Venezuela     0.937730   0.858785       0.992836\n155             Vietnam     0.993886   0.968988       0.996043\n156  West Bank and Gaza     0.989750   0.978440       0.992071\n157              Zambia     0.017681   0.659222       0.989683\n158            Zimbabwe          NaN        NaN            NaN\n\n[159 rows x 4 columns]\n"
    }
   ],
   "source": [
    "## For each country, find the 'Time' reference since patient 1, and the corrsponding date\n",
    "Output = pd.DataFrame() #Temporary empty dataframe\n",
    "Cols = ['Country', 'Logistic R2', 'Linear R2', 'Polynomial R2']\n",
    "Output = pd.DataFrame(columns = Cols)\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Pred2_Data[Pred2_Data.Country.eq(Country)]\n",
    "    data_cntry =data_cntry.dropna()\n",
    "\n",
    "    Logŷ = data_cntry['Logistic Prediction'].values\n",
    "    Linŷ = data_cntry['Linear Prediction'].values\n",
    "    Polŷ = data_cntry['Polynomial Prediction'].values\n",
    "    y = data_cntry['Confirmed'].values\n",
    "\n",
    "\n",
    "\n",
    "    n = data_cntry.count(axis='columns').count()\n",
    "    p = 1\n",
    "\n",
    "    LogAdjR2 = adj_r_squared(Logŷ, y)\n",
    "    LinAdjR2 = adj_r_squared(Linŷ, y)\n",
    "    PolAdjR2 = adj_r_squared(Polŷ, y)\n",
    "\n",
    "\n",
    "    Output = Output.append({'Country': Country, 'Logistic R2': LogAdjR2, 'Linear R2': LinAdjR2, 'Polynomial R2': PolAdjR2,}, ignore_index=True)\n",
    "\n",
    "print(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now() # current date and time\n",
    "Now = now.strftime(\"%Y%m%d_%Hh%M\")\n",
    "\n",
    "Pred2_Data.to_csv(f'C:\\\\Users\\\\JMSch\\\\Documents\\\\MEGA\\\\05_Paris\\\\ESCP Business School\\\\MSc Big Data & Business Analytics\\\\COVID19\\\\COVID19\\\\Data\\\\Extracts\\\\ALL_Prediction_Output_Global_{Now}.csv', index = False)\n",
    "\n",
    "Output.to_csv(f'C:\\\\Users\\\\JMSch\\\\Documents\\\\MEGA\\\\05_Paris\\\\ESCP Business School\\\\MSc Big Data & Business Analytics\\\\COVID19\\\\COVID19\\\\Data\\\\Extracts\\\\Predictions_Adjusted_R-Squared_{Now}.csv', index = False)"
   ]
  }
 ]
}