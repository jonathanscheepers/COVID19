{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit6d5b94c2ec1f4c3aacebeb2f43447b95",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta  \n",
    "import dateutil.parser\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import fsolve\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time horizon D+x for making regression predictions\n",
    "Prediction_Horizon = 14\n",
    "## Starting point for minimal number of confirmed cases\n",
    "Min_Confirmed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "794900"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "url = 'https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv'\n",
    "myfile = requests.get(url)\n",
    "open(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', 'wb').write(myfile.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', sep = ',')\n",
    "data = data[1:]\n",
    "\n",
    "## Choosing the columns for later use\n",
    "data = data.filter(['Country/Region', 'Date', 'Value'])\n",
    "## Renaming the columns we are going to use\n",
    "data.columns = ['Country', 'Date', 'Value']\n",
    "## Transforming the value to int\n",
    "data['Value'] = data['Value'].astype(int)\n",
    "data['Date'] = data['Date'].astype('datetime64[D]')\n",
    "## Summing values for 'Value' for which there are multiple records for one coutry on one day\n",
    "data['Total'] = data.groupby(['Country', 'Date'])['Value'].transform('sum')\n",
    "## Delete the duplicate records\n",
    "data = data.drop_duplicates(subset=['Country', 'Date'])\n",
    "## Sort the value from earliest to latest\n",
    "data = data.sort_values(['Date'], ascending = True)\n",
    "data.columns = ['Country', 'Date', 'Value', 'Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the dates of which no infections were reported\n",
    "data = data[data.Confirmed > Min_Confirmed]\n",
    "\n",
    "## Assign a t value to each date from the first reported infection\n",
    "#data.insert(loc=0, column='Time', value=np.arange(len(data))+1)\n",
    "\n",
    "## Transform the date from Excel numbers to Python dates\n",
    "#data['Date'] = data['Date'].apply(lambda x: x -2)\n",
    "data['Date'] = data['Date'].astype('datetime64[D]') \n",
    "data['Date'] = data['Date'].dt.strftime('%d/%m/2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "data['Time'] = 1\n",
    "data = data.sort_values(by=['Country', 'Confirmed'])\n",
    "data.index = range(len(data))\n",
    "\n",
    "for index, row in data.iloc[1:].iterrows():\n",
    "    if data.loc[index, 'Country'] == data.loc[(int(index) - 1), 'Country']: \n",
    "        data_new = data[data.Country.eq(data.loc[index, 'Country'])]\n",
    "        HighestForCountry = data_new['Time'].max()\n",
    "        data.loc[index, 'Time'] = HighestForCountry + 1\n",
    "    else:\n",
    "        data.loc[index, 'Time'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Countries = data['Country'].tolist()\n",
    "Countries = list(dict.fromkeys(Countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Days' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3b08dd0b0503>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtoday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m## Selecting the timeframe for building the regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mLastWeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoday\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mLastWeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLastWeek\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%d/%m/%Y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Days' is not defined"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "## Selecting the timeframe for building the regression\n",
    "LastWeek = today - timedelta(days=Days) \n",
    "LastWeek = LastWeek.strftime(\"%d/%m/%Y\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_Data = pd.DataFrame()\n",
    "\n",
    "## For each country, find the 'Time' reference since patient 1, and the corrsponding date\n",
    "for Country in Countries:\n",
    "    data_sub = data[data['Country'].eq(Country)]\n",
    "    Current_Horizon = int(max(data_sub['Time']))\n",
    "    FindDate = data_sub['Date'].iloc[-1]\n",
    "    MaxDate = dateutil.parser.parse(FindDate).date()\n",
    "\n",
    "## For each country, add the number of days to the prediction horizon of the dataset based on the 'Time' reference and date\n",
    "    for i in range(Prediction_Horizon):\n",
    "        New_Time = int(max(data_sub['Time'])) + 1\n",
    "        Days_Delay = (New_Time - Current_Horizon)\n",
    "        New_Date = MaxDate + timedelta(days=Days_Delay) \n",
    "        New_Date = New_Date.strftime(\"%d/%m/%Y\")\n",
    "        data_sub = data_sub.append({'Country': Country,'Date': New_Date, 'Time': New_Time},ignore_index=True)\n",
    "    Full_Data = pd.concat([Full_Data,data_sub]) \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Polynomial_Regression(t):\n",
    "    return pol_reg.predict(poly_reg.fit_transform([[t]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countries = ['Afghanistan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "## building the model per country\n",
    "Pred_Data = pd.DataFrame()\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Full_Data[Full_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 8:\n",
    "        try:\n",
    "            Model_Data = data_cntry.dropna()\n",
    "            Model_Data = Model_Data[['Time','Confirmed']]\n",
    "\n",
    "            X = Model_Data[['Time']]\n",
    "            y = Model_Data[['Confirmed']]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=0)\n",
    "\n",
    "            #lin_reg = LinearRegression()\n",
    "            #lin_reg.fit(X, y)\n",
    "\n",
    "            poly_reg = PolynomialFeatures(degree=4)\n",
    "            X_poly = poly_reg.fit_transform(X)\n",
    "            pol_reg = LinearRegression()\n",
    "            pol_reg.fit(X_poly, y)\n",
    "\n",
    "            ## This code transforms the regression coefficients into floats to use in our prediction function\n",
    "\n",
    "            data_cntry.insert(5,'Predictions',0)\n",
    "            data_cntry['Predictions'] = data_cntry['Time'].apply(Polynomial_Regression)\n",
    "            \n",
    "            ## remove first set of square brackets from prediciton output\n",
    "            data_cntry['Predictions'] = data_cntry['Predictions'].str[0]\n",
    "            ## remove second set of square brackets from prediciton output\n",
    "            data_cntry['Predictions'] = data_cntry['Predictions'].str[0]\n",
    "            ## \n",
    "            data_cntry['Predictions'] =  data_cntry['Predictions'].astype(float)\n",
    "\n",
    "            Pred_Data = pd.concat([Pred_Data,data_cntry]) \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now() # current date and time\n",
    "\n",
    "Now = now.strftime(\"%Y%m%d_%Hh%M\")\n",
    "\n",
    "Pred_Data.to_csv(f'C:\\\\Users\\\\JMSch\\\\Documents\\\\MEGA\\\\05_Paris\\\\ESCP Business School\\\\MSc Big Data & Business Analytics\\\\COVID19\\\\COVID19\\\\Data\\\\Polynomial_Prediction_Output_Global_{Now}.csv', index = False)"
   ]
  }
 ]
}