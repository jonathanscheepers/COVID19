{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit6d5b94c2ec1f4c3aacebeb2f43447b95",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta  \n",
    "import dateutil.parser\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import fsolve\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time horizon D+x for making regression predictions\n",
    "Prediction_Horizon = 14\n",
    "## Starting point for minimal number of confirmed cases\n",
    "Min_Confirmed = 10\n",
    "\n",
    "## select country for analysis\n",
    "Country = 'France'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "794900"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "url = 'https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv'\n",
    "myfile = requests.get(url)\n",
    "open(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', 'wb').write(myfile.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\JMSch\\Documents\\MEGA\\05_Paris\\ESCP Business School\\MSc Big Data & Business Analytics\\COVID19\\COVID19\\Data\\time_series_covid19_confirmed_global_narrow(all).csv', sep = ',')\n",
    "data = data[1:]\n",
    "\n",
    "## Choosing the columns for later use\n",
    "data = data.filter(['Country/Region', 'Date', 'Value'])\n",
    "## Renaming the columns we are going to use\n",
    "data.columns = ['Country', 'Date', 'Value']\n",
    "## Transforming the value to int\n",
    "data['Value'] = data['Value'].astype(int)\n",
    "data['Date'] = data['Date'].astype('datetime64[D]')\n",
    "## Summing values for 'Value' for which there are multiple records for one coutry on one day\n",
    "data['Total'] = data.groupby(['Country', 'Date'])['Value'].transform('sum')\n",
    "## Delete the duplicate records\n",
    "data = data.drop_duplicates(subset=['Country', 'Date'])\n",
    "## Sort the value from earliest to latest\n",
    "data = data.sort_values(['Date'], ascending = True)\n",
    "data.columns = ['Country', 'Date', 'Value', 'Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the dates of which no infections were reported\n",
    "data = data[data.Confirmed > Min_Confirmed]\n",
    "\n",
    "## Assign a t value to each date from the first reported infection\n",
    "#data.insert(loc=0, column='Time', value=np.arange(len(data))+1)\n",
    "\n",
    "## Transform the date from Excel numbers to Python dates\n",
    "#data['Date'] = data['Date'].apply(lambda x: x -2)\n",
    "data['Date'] = data['Date'].astype('datetime64[D]') \n",
    "data['Date'] = data['Date'].dt.strftime('%d/%m/2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "data['Time'] = 1\n",
    "data = data.sort_values(by=['Country', 'Confirmed'])\n",
    "data.index = range(len(data))\n",
    "\n",
    "for index, row in data.iloc[1:].iterrows():\n",
    "    if data.loc[index, 'Country'] == data.loc[(int(index) - 1), 'Country']: \n",
    "        data_new = data[data.Country.eq(data.loc[index, 'Country'])]\n",
    "        HighestForCountry = data_new['Time'].max()\n",
    "        data.loc[index, 'Time'] = HighestForCountry + 1\n",
    "    else:\n",
    "        data.loc[index, 'Time'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Countries = [Country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "## Selecting the timeframe for building the regression\n",
    "LastWeek = today - timedelta(days=Days) \n",
    "LastWeek = LastWeek.strftime(\"%d/%m/%Y\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_Data = pd.DataFrame()\n",
    "\n",
    "## For each country, find the 'Time' reference since patient 1, and the corrsponding date\n",
    "for Country in Countries:\n",
    "    data_sub = data[data['Country'].eq(Country)]\n",
    "    Current_Horizon = int(max(data_sub['Time']))\n",
    "    Days = Current_Horizon\n",
    "    FindDate = data_sub['Date'].iloc[-1]\n",
    "    FindDate = datetime.strptime(FindDate, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "    MaxDate = dateutil.parser.parse(FindDate).date()\n",
    "\n",
    "## For each country, add the number of days to the prediction horizon of the dataset based on the 'Time' reference and date\n",
    "    for i in range(Prediction_Horizon):\n",
    "        New_Time = int(max(data_sub['Time'])) + 1\n",
    "        Days_Delay = (New_Time - Current_Horizon)\n",
    "        New_Date = MaxDate + timedelta(days = Days_Delay)\n",
    "        New_Date = New_Date.strftime(\"%d/%m/%Y\")\n",
    "        data_sub = data_sub.append({'Country': Country,'Date': New_Date, 'Time': New_Time},ignore_index=True)\n",
    "    Full_Data = pd.concat([Full_Data,data_sub]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Full_Data[Full_Data.Country.eq(Country)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # function to be minimized\n",
    "def f_sigmoid(x, a, b, c):\n",
    "    # a = sigmoid midpoint\n",
    "    # b = curve steepness (logistic growth)\n",
    "    # c = max value\n",
    "        return (c / (1 + np.exp(-b*(x-a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "France\n"
    }
   ],
   "source": [
    "## building the model per country\n",
    "Pred_Data = pd.DataFrame()\n",
    "#Full_Data = pd.DataFrame()\n",
    "\n",
    "for Country in Countries:\n",
    "    data_cntry = Full_Data[Full_Data.Country.eq(Country)]\n",
    "    if data_cntry.count(axis='columns').count() > 0:\n",
    "        try:\n",
    "            \n",
    "            data_cntry = data_cntry[['Country', 'Time','Confirmed','Date']]\n",
    "  \n",
    "            Model_Data = data_cntry.dropna()\n",
    "            x = Model_Data['Time'].values\n",
    "            y = Model_Data['Confirmed'].values\n",
    "\n",
    "            print(Country)\n",
    "            # fitting the data on the logistic function\n",
    "    \t    # A: sigmoid midmoint\n",
    "            # B: curve steepness (logistic growth)\n",
    "            # C: max value\n",
    "            popt_sig, pcov_sig = curve_fit(f_sigmoid, x, y, method='dogbox', bounds=([20., 0.001, y.mean()],[60., 2.5, 10*y.max()]), maxfev=5000)\n",
    "            #print(popt_sig)\n",
    "\n",
    "            Pred_Length = data_cntry['Confirmed'].values\n",
    "\n",
    "            x_m = np.arange(len(Pred_Length))\n",
    "            y_m = f_sigmoid(x_m, *popt_sig)\n",
    "\n",
    "            data_cntry['Predictions']=pd.Series(y_m)\n",
    "\n",
    "            Pred_Data = pd.concat([Pred_Data,data_cntry]) \n",
    "\n",
    "        except:\n",
    "           continue\n",
    "\n",
    "    else:\n",
    "            continue\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Country  Time  Confirmed        Date    Predictions\n50  France    51    40708.0  29/03/2020   37660.044304\n51  France    52    45170.0  30/03/2020   42231.281592\n52  France    53    52827.0  31/03/2020   47003.564654\n53  France    54    57749.0  01/04/2020   51910.241357\n54  France    55        NaN  02/04/2020   56876.533068\n55  France    56        NaN  03/04/2020   61823.948474\n56  France    57        NaN  04/04/2020   66675.179003\n57  France    58        NaN  05/04/2020   71358.839581\n58  France    59        NaN  06/04/2020   75813.452367\n59  France    60        NaN  07/04/2020   79990.232358\n60  France    61        NaN  08/04/2020   83854.471667\n61  France    62        NaN  09/04/2020   87385.565157\n62  France    63        NaN  10/04/2020   90575.914022\n63  France    64        NaN  11/04/2020   93429.052713\n64  France    65        NaN  12/04/2020   95957.366301\n65  France    66        NaN  13/04/2020   98179.720331\n66  France    67        NaN  14/04/2020  100119.243382\n67  France    68        NaN  15/04/2020  101801.411572",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Time</th>\n      <th>Confirmed</th>\n      <th>Date</th>\n      <th>Predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>50</th>\n      <td>France</td>\n      <td>51</td>\n      <td>40708.0</td>\n      <td>29/03/2020</td>\n      <td>37660.044304</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>France</td>\n      <td>52</td>\n      <td>45170.0</td>\n      <td>30/03/2020</td>\n      <td>42231.281592</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>France</td>\n      <td>53</td>\n      <td>52827.0</td>\n      <td>31/03/2020</td>\n      <td>47003.564654</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>France</td>\n      <td>54</td>\n      <td>57749.0</td>\n      <td>01/04/2020</td>\n      <td>51910.241357</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>France</td>\n      <td>55</td>\n      <td>NaN</td>\n      <td>02/04/2020</td>\n      <td>56876.533068</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>France</td>\n      <td>56</td>\n      <td>NaN</td>\n      <td>03/04/2020</td>\n      <td>61823.948474</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>France</td>\n      <td>57</td>\n      <td>NaN</td>\n      <td>04/04/2020</td>\n      <td>66675.179003</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>France</td>\n      <td>58</td>\n      <td>NaN</td>\n      <td>05/04/2020</td>\n      <td>71358.839581</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>France</td>\n      <td>59</td>\n      <td>NaN</td>\n      <td>06/04/2020</td>\n      <td>75813.452367</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>France</td>\n      <td>60</td>\n      <td>NaN</td>\n      <td>07/04/2020</td>\n      <td>79990.232358</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>France</td>\n      <td>61</td>\n      <td>NaN</td>\n      <td>08/04/2020</td>\n      <td>83854.471667</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>France</td>\n      <td>62</td>\n      <td>NaN</td>\n      <td>09/04/2020</td>\n      <td>87385.565157</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>France</td>\n      <td>63</td>\n      <td>NaN</td>\n      <td>10/04/2020</td>\n      <td>90575.914022</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>France</td>\n      <td>64</td>\n      <td>NaN</td>\n      <td>11/04/2020</td>\n      <td>93429.052713</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>France</td>\n      <td>65</td>\n      <td>NaN</td>\n      <td>12/04/2020</td>\n      <td>95957.366301</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>France</td>\n      <td>66</td>\n      <td>NaN</td>\n      <td>13/04/2020</td>\n      <td>98179.720331</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>France</td>\n      <td>67</td>\n      <td>NaN</td>\n      <td>14/04/2020</td>\n      <td>100119.243382</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>France</td>\n      <td>68</td>\n      <td>NaN</td>\n      <td>15/04/2020</td>\n      <td>101801.411572</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "Pred_Data[50:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now() # current date and time\n",
    "\n",
    "Now = now.strftime(\"%Y%m%d_%Hh%M\")\n",
    "\n",
    "Pred_Data.to_csv(f'C:\\\\Users\\\\JMSch\\\\Documents\\\\MEGA\\\\05_Paris\\\\ESCP Business School\\\\MSc Big Data & Business Analytics\\\\COVID19\\\\COVID19\\\\Data\\\\Extracts\\\\Logistic_Prediction_Output_Global_{Country}.csv', index = False)"
   ]
  }
 ]
}